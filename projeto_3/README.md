# Projeto #3 - Meu primeiro projeto de IA

## Prazo - **01/08/2020**

## Introdução

No primeiro projeto do curso tivemos contato com uma análise explorátoria de dados, uma das tarefas mais recorrentes na rotina de um cientista de dados. 

Nessa atividade o profissional busca remover dados inconsistentes da base, com valores fora do domínio ou do interesse. Por exemplo removendo registros com valores não preenchidos, ou segmentando a base por um determinado critério. Também se busca entender como esse dado está organizado e como as diversas variáveis existes se relacionam.

Nesse ponto do curso já tivemos acesso a muito mais ferramentas e podemos fazer uma análise de dados muito mais profunda e completa!

## Objetivo

O objetivo desse projeto é realizar uma análise exploratória de dados sobre uma base de interesse, que esteja de acordo com os critérios definidos. Recomendamos a escolha de uma base do [Kaggle](https://www.kaggle.com/) em um tema de interesse ou que você tenha conhecimento sobre, isso facilita muito o processo de investigação.

Vale observar que se a base do primeiro projeto obedecer os critérios estabelecidos pode ser utilizada, caso contrário procure uma base nova para o trabalho. Lembre das lições aprendidas sobre a escolha da base, diversidade de informações ajuda na criatividade da exploração.

Ao contrário que aconselhamos no primeiro projeto, bases reais do seu contexto profissional atual são bem vindas =)

## Instruções

Leia atentamente as instruções abaixo:

1. Escolha de uma base do [Kaggle](https://www.kaggle.com/) em um tema de interesse ou que você tenha conhecimento sobre, isso facilita muito o processo de investigação.

   1. A base escolhida deve conter no mínimo as seguintes características:

   - Mais de 10 mil registros
   - Tenha em mente que menos de 20 features podem limitar suas análises 
   - Não limitaremos os tipos de features uma vez que bases com imagens ou texto podem ser utilizadas nesse trabalho.
   - Não serão permitidas bases já pre-processadas e com features normalizadas.
   - A combinação de bases é bem vinda.
   - Exista um problema de classificação ou regressão associado.

1. Muito mais que definir os critérios mínimos desse desafio, essas características vão tornar possível que uma análise realista seja feita. Bases muito mais simples que isso irão tornar sua análise pobre e distante do que é o dia a dia de um profissional da área.

1. Crie o projeto em seu GitHub. Dê o nome de `aed_projeto_3`

1. Pegue o template de notebook nesse repositório e utilize-o como base para seu projeto. Importante, siga as instruções do notebook e a estrutura dele.

1. Não modifique a estrutura do notebook. Se algo estiver te atrapalhando ou dificultando, converse com um dos professores ou seus colegas no Slack.

1. Use o Slack da turma para conversar sobre o curso. Não iremos responder dúvidas via e-mail.

1. A entrega e correção será feita via GitHub. Assim sendo, ao término da atividade faça o `git commit` e o `git push` das suas análises já executadas no notebook.

1. Existem dois tipos de bloco no notebook para respostas. Algumas devem ser respondidas com código outras apenas com um texto explicativo.

1. Abuse de gráficos, eles facilitam o entendimento das análises e ajudam na observação de eventos e massas de dados grandes. Mas atenção à escolha do tipo correto de visualização e das melhores (e piores) práticas de visualização para cada estilo de gráfico (**será um critério de avaliação**). Use como referência o [data-to-viz](https://www.data-to-viz.com/).

## Critérios de avaliação

Sabemos do projeto 1 que **clareza** e **corretude** das análises são fundamentais para suportar suas conclusões, mas agora somados a esses critérios queremos ver profundidade na avaliação. Vamos desconsiderar análises superficiais como o valor médio de um determinado atributo ou a proporção de exemplos em categorias, queremos ir além. Por exemplo, o que 20% de exemplos da categoria A quer dizer? Será que eles se comportam de forma diferente das demais categorias? Será que 20% da categoria A represeta a realidade, como é essa distribuição em outros ambientes?

Cada um dos exercícios possui seu peso associado.

## Links utéis e referências

- [Jupyter](https://jupyterlab.readthedocs.io/en/stable/user/notebook.html)
- [Python 3.7](https://docs.python.org/3.7/library/index.html)
- Visualização:
	- [data-to-viz](https://www.data-to-viz.com/)
	- [visualização básica](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html)
	- [visualização de dados faltantes](https://github.com/ResidentMario/missingno)
- [Kaggle](https://www.kaggle.com/)
- [Data Mining: Concepts and Techniques](https://www.elsevier.com/books/data-mining-concepts-and-techniques/han/978-0-12-381479-1)
